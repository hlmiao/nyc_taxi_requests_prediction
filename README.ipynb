{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi Requests Prediction\n",
    "\n",
    "ABC company is a ride hailing company, they have large volume of subscribe users using their mobile app to get transportation services from local drivers. The mobile app for passengers and drivers will upload activities data to server for data analyst. ABC company wants to leverage AI/Machine Learning technologies to improve their business. One of their key requirements is demand forecast. They prefer to split a city into different grid, and forecast the demand in each grid at 30min slot. If the demand goes high in future, ABC company will increase the price in that grid to slow down the demands.\n",
    "\n",
    "To demonstrate the demand forecast in each grid at 30min slot, we use the yellow New York City Taxi and Limousine Commission (TLC) Trip Record Data between April 2018 and June 2018 in Manhattan from AWS public datasets as source data (https://registry.opendata.aws/nyc-tlc-trip-records-pds/). We split the dataset into train part (2018.04.01-2018.05.31) and validate part (2018.06.01-2018.06.30). We demonstrate 3 methods to forecast demand: XGBoost, LightGBM, linear regression implemented using sklearn, and evaluate the models using mean absolute error (MAE).\n",
    "\n",
    "We mainly use linear regression algorithm as the baseline algorithm, and use XGBoost as the main algorithm. XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way.\n",
    "\n",
    "To run this notebook, you have to download trip data from Amazon S3 bucket to nyc_tlc directory in your computer:\n",
    "\n",
    "## [Question 1]\n",
    "\n",
    "Download data and unzip archive file commands\n",
    "\n",
    "<pre>\n",
    "https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2018-04.csv\n",
    "https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2018-05.csv\n",
    "https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2018-06.csv\n",
    "https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
    "https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip (unzip)\n",
    "</pre>\n",
    "\n",
    "After download, your local directory structure should be:\n",
    "\n",
    "<pre>\n",
    "nyc_tlc\n",
    "├── misc\n",
    "│   ├── taxi_zone_lookup.csv\n",
    "│   ├── taxi_zones\n",
    "│   │   ├── taxi_zones.dbf\n",
    "│   │   ├── taxi_zones.prj\n",
    "│   │   ├── taxi_zones.sbn\n",
    "│   │   ├── taxi_zones.sbx\n",
    "│   │   ├── taxi_zones.shp\n",
    "│   │   ├── taxi_zones.shp.xml\n",
    "│   │   └── taxi_zones.shx\n",
    "│   └── taxi_zones.zip\n",
    "└── trip_data\n",
    "    ├── yellow_tripdata_2018-04.csv\n",
    "    ├── yellow_tripdata_2018-05.csv\n",
    "    └── yellow_tripdata_2018-06.csv\n",
    "\n",
    "3 directories, 12 files\n",
    "</pre>\n",
    "\n",
    "### Basic Prepare\n",
    "\n",
    "We import all useful packages, and set the `first_datetime` to 2018-04-01 00:00:00, and `last_datetime` to 2018-07-01 00:00:00. We split the dataset into two parts: train and validate, by setting the `train_valid_split_datetime` to 2018-06-01 00:00:00.\n",
    "\n",
    "### Taxi Zones\n",
    "\n",
    "Since newest NYC Taxi dataset only provides `PULocationID` and `DOLocationID`, instead of `pickup_longitude`, `pickup_latitude`, `dropoff_longitude`, and `dropoff_latitude` in previous dataset, we can only predict requests in each `PULocationID` (zone). We load [taxi _zone_lookup.csv] and [taxi_zones.shp], and use `geopandas` to visualize the zones in Manhattan (69 in total).\n",
    "\n",
    "### Data Prepare\n",
    "\n",
    "We load all data from [nyc_tlc/trip_data/] between April and June 2018, and filter abnormal data. We use `matplotlib` and `geopandas` to visualize some columns and help us to understand the trip data.\n",
    "\n",
    "## [Question 2]\n",
    "\n",
    "1. load Manhattan data: from 2018-04 to 2018-06\n",
    "2. define a function 'filter_abnormal_data' to filter abnormal data\n",
    "3. call filter_abnormal_data to filter 'contest_helper.NycTaxiAnalyzer.data'\n",
    "\n",
    "## [Question 3]\n",
    "\n",
    "Show statistics of the prepared sample data. \n",
    "\n",
    "## [Challenge Question]\n",
    "\n",
    "Add new prediction algorithm.\n",
    "\n",
    "### Feature Prepare\n",
    "\n",
    "We set the `30min_id` to represent 30min slot. For example, time between 2018-01-01 00:00:00 and 2018-01-01 00:05:00 has a `5min_id` as 0, and time between 2018-01-01 00:05:00 and 2018-01-01 00:10:00 has a `5min_id` as 1, and the similar with `15min_id` and `30min_id`. For each `Xmin_id` (X represents 5, 15 or 30), we predict the requests in all 69 zones. We have some `static features` such as `month`, `day`, `hour`, `weekday`, `is_weekend`, `is_morning_peak`, `is_evening_pick` for all `Xmin_id` and zones. Also we can extend more static features such as weather and zone features. Other `dynamic features` includes requests in `5min ago`, `10min ago`, `15min ago`, `7days ago`, etc. Also we can extend more dynamic features such as total passengers in 5min ago. At last, we generate 34 features for each `Xmin_id` and zone.\n",
    "\n",
    "### Train and Validate\n",
    "\n",
    "We split all data into train and validate part. We demonstrate 3 methods to forecast requests: XGBoost, LightGBM, linear regression implemented using sklearn, and evaluate the models using mean absolute error (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
